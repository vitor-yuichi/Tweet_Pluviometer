\chapter{THEORY FUNDAMENTALS}\label{Rev}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Floods}\label{flood}

Flooding is a complex phenomenon, as its cause is interrelated to a range of parameters such as climate, urban structural faults, inadequate drainage systems, hydrographic basins, proximity to water bodies, inappropriate use and occupation of the soil, among others \cite{doocy2013human}.

The absence of urban planning and the rapid modification of the space culminate in soil sealing, contributing to a reduction in concentration time and an increase in the volume of surface runoff, thus amplifying the peak flow and consequently saturating the site's rainwater drainage \cite{hansmann2013descriccao}.

The local topography is also a preponderant factor for the occurrence of flooding, since it has already been verified that the places with the highest frequency of flooding have flat morphometric characteristics, depressions or valley bottoms, hindering the local runoff process \cite{braga2016alagamentos}.

Also, due to the population's lack of environmental education, the inadequate disposal of solid waste appears as another factor causing the obstruction of the local drainage system, once again leading to flooding.

%\section{Social media for flood monitoring}\label{social}

%The development of society in the technological sphere allowed the meteoric rise of social networks and their functionalities.
%The massive amount of data generated by these networks consolidates the interaction of the virtual universe with the concrete world, where users express their perceptions and emotions about the surrounding events \cite{naaman2011geographic}. 

%The activity of social networks and their spatial heterogeneity demonstrate the potential for monitoring meteorological events \cite{de2021effect}. Meanwhile, the work of \citen{horita2015development} integrates these platforms for flood risk management.

%The use of social networks shows a growing trend regarding their incorporation in research for the monitoring and analysis of different types of events. According to \citen{de2015geographic}, the use of voluntary geographic information, mainly from the Twitter network, is a fundamental component for greater awareness of disaster events. Thus consolidating a better perception of the environment, in addition to enabling greater understanding of the possible consequences of phenomena such as precipitation \cite{vitorbrasil}.

%\section{Classification}\label{class}

%Machine Learning Techniques are increasingly employed in the study of natural disasters. Some researches use such techniques to analyze the semantics linked to posts on social networks, thus allowing to improve the classification results of a certain type of event \cite{de2015geographic, deparday2019machine}.

%Classification comprises the widely used methods for associating each item in a data series with a particular class. Formally, the classification is described by a function $F: \mathcal{X} \rightarrow \mathcal{Y}$ that associates elements in the attribute set \(\mathcal{X}\) to a class of \(\Omega= \{\omega_1, \omega_2,...,\omega_n\}\), with \(n \in \mathbb{N}^*\) through a class indicator \(\mathcal{Y} \in \{1,2,...,n\}\). Under these conditions, when \(x \in \mathcal{X}\) and \(y \in \mathcal{Y}\), the function \(y=F(x)\) indicates that $x$ belongs to \(\Omega_y\). Regarding the supervised learning classification models, the function \(F\) makes use of information extracted from the training set \(\mathcal{D}=\{(x_j,\omega_j) \in \mathcal{X} \times \Omega : i=1,...,m \}\).

%Among several existing proposals in the literature, \textit{Support Vector Machine} (SVMs), \textit{Random Forest} (RF) and \textit{Multilayer Perceptron} (MLP) are frequently used in the most diverse application domains.
%\subsection{SVM}

%The SVM method distinguishes between training examples based on a hyperplane with greater margin of separation, either in the original data space or conveniently remapped. According to \citen{lian2006multi}, this method is used by several authors due to its high accuracy and generalizability.

%The hyperplane corresponds to the locus where \(f(x)=\langle w,x \rangle+b\) is null. The variable \(w\) is the vector orthogonal to the hyperplane and \(b\) the distance between the hyperplane and the origin of the attribute space.
%The determination of the hyperplane with the largest separation margin is obtained by optimizing the \cite{theodoridis2010introduction} problem:

%\begin{equation}
	%\begin{array}{l}
		%\max_\gamma (\sum^m_{i=1} %\gamma_i-\frac{1}{2}\sum^m_{i=1}\sum^m_{j=1}\g%amma_i \gamma_j y_i y_j \ langle x_i,x_j %\rangle) \\
		
		%\textrm{subject to } \begin{cases}
		%	0 \leq \gamma_i \leq C, i=1,...,m \\
		%	\sum^m_{i=1} \gamma_i y_i=0
		%\end{cases}
	%\end{array}
%\end{equation}
%where $C$ is the parameter used to regularize the hyperplane and \(\gamma_i\) are Lagrange multipliers.

%The definition of the parameters that determine the hyperplane are $w=\sum_{\forall x_i \in SV}y_i \gamma_i x_i$ and $b=\frac{1}{\#SV}(\sum_{x_i \in SV} y_i+ \sum_{x_i \in SV} \cdot \sum_{x_j \in SV} \gamma_i \gamma_j y_i y_j \langle x_i,x_j \rangle)$, where $SV$ is a subset of the samples in \(\mathcal{ D}\) such that $\gamma_i \neq 0$, denoted by support vectors. Finally, the indication of the class associated with the analyzed vector is given by the sign of the discriminant function \(f(x)\) \cite{maselli2019integraccao}.

%\subsection{RF}

%The RF method has been widely used in applications related to the identification of hydrological events. In \citen{zhu2021flood} and \citen{liu2020random} the potential of this method in evaluating the resilience and identifying spatial patterns of flooding is demonstrated.
%In a superficial way, according to \citen{breiman2001random}, this method is represented by a set of decision trees that combine their respective outputs through a majority voting scheme in order to make a final decision.

%\subsection{MLP}

%The MLP method has been used to issue hydrological alerts and susceptibility mappings \cite{da2016utilizaccao,pacheco2020mapeamento}.

%This method comprises a system of weighted connections between artificial neurons distributed in different layers. Mathematically the layers of input and output neurons are vectors $\mathbf{i}$ and $\mathbf{o}$, respectively, and the weights structured in a matrix $\mathbf{W}$. Under these conditions, the output of the network is given by $\mathbf{o}= f( \mathbf{iW}) $, where $f(x)\begin{cases}
%	1, \ x>0 \\
%	0, \ \textrm{otherwise}
%\end{cases}$, acts as an activation function for the input $x$ presented.
%Assuming that $\mathbf{t}$ is the expected output, the associated error is calculated through $E(\mathbf{o})=\mathbf{t}-\mathbf{o}=\mathbf{t}- f(\mathbf{iW})$.
%The MLP training process is given by updating the weights in $\mathbf{W}$ in order to minimize $E(\mathbf{o})$ errors.

\section{Statistics}

Statistics is a fundamental discipline to provide method and tools to find deeper insight into data. Data science and Machine Learning need the concepts of statistics to build more sophisticated models and analyses. 

One of the fundamental structures of statistics is the hypothesis test which establishes a direct relationship between theory and statistics, since hypotheses can be tested with data \cite{weihs2018data}.

\section{Correlation}

Correlation is a relationship between two variables represented by ordered pairs $(x,y)$ with $x$ the independent variable and y the dependent variable. In Data Science, correlations are widely used to establish statistical relationships and inferences with greater precision.

However, the correlation does not imply causality, it must be analyzed whether a variable $x$ causes $y$, in addition to verifying if there is a cause between the two variables through a third, thus discarding that there is only a correlation by sheer coincidence \cite{larson2004estatistica}. 

The most used test for parametric tests is the Pearson coefficient. Given a sample of $X$ and $Y$, the Pearson coefficient is calculated by the equation \ref{pearson}, where $\rho$ is correlation degree ranging from 0 to 1. 
 \begin{equation}\label{pearson}
 	 \rho=\frac{cov(X,Y)}{\sqrt{var(X)\cdot var(Y)}}
 \end{equation}

For non-parametric tests, descriptive statistics uses Spearman's coefficient. Pearson's correlation assesses linear relations, Spearman's correlation assesses monotonous relationships, whether linear or not. This correlation is described by the equation \ref{spear}, where $n$ is the number of samples, $d$ is the differences between ranks and $\pho$ is the correlation.
\begin{equation}\label{spear}
	\rho=1-\frac{6\sum d^2}{n^2(n^2-1)}
\end{equation}

\section{Normality test}
To apply the correct test, it is necessary to determine the distribution using the Shapiro Wilk test, which consists of a normality test. Assuming that the null hypothesis assumes that the sample has a normal distribution. The $W$ test statistic for normality is defined by the \ref{shapiros} equation. Where $y$ is the variable in the sample and $a$ the tabulated coefficient.  

\begin{equation}\label{shapiros}
	W=\frac{b^2}{S^2}=\frac{(\sum^n_{i=1}a_iy_i)^2}{{\sum^n_{i=1}(y_i-\bar{y_i}))^2}}}
\end{equation}

\section{Mann Whitney Test}

This non-parametric test is used to determine whether there is a difference between two groups of data \cite{perme2019confidence}. The null  $H_0$ determines that two analyzed series $X$ and $Y$ are equal. if your if $p$ is less than the significance $\alpha=0.05$, the null hypothesis is rejected \cite{macfarland2016mann}. The statistical test was divided among the three months studied, applied in the first month, then in the two consecutive months, and finally, the entire temporal window, in which the variable $X$ represents the temporal distribution of words on the days that flooding occurred and $Y$ the distribution on days without flooding.

%Machine Learning uses several statistical techniques to predict and infer data. However, statistics have a greater emphasis on inference. The evaluation of a supervised classification algorithm can be performed using statistical techniques such as cross-validation and P-values of tests \cite{ij2018statistics}. 

 